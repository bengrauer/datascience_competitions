{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====================================================================================================\n",
    "# Author: Ben Grauer\n",
    "# Purpose: General notebook for feature / model runs and submission (after all pre-processing of files)\n",
    "#\n",
    "#====================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workDir = 'D:/project/data/kg_avito_demand/'\n",
    "fileTest = 'test.csv'\n",
    "fileTrain = 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard function to output submission files\n",
    "def output_submission_file(df, modelType):\n",
    "    # Set a time-stamp\n",
    "    timestamp = datetime.datetime.today().strftime('%Y%m%d_%H%M%S')\n",
    "    # output the file\n",
    "    df.to_csv(index=False, path_or_buf=workDir + '/results/results_' + modelType + '_' + timestamp + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Train and Test Files\n",
      "0:00:29.147204\n",
      "Adding Stats Features\n",
      "Total Train Records: 1503424\n",
      "Total Test Records: 508438\n",
      "0:00:59.490065\n",
      "Cleaning data\n",
      "0:01:02.468101\n",
      "Loading Image + Text Data\n",
      "Loading Train Image Stat Files (3-splits)\n",
      "0:01:36.308608\n",
      "Loading Test Image Stat Files\n",
      "0:01:47.407927\n",
      "Loading Text Stat Files\n",
      "0:02:15.903773\n",
      "Merging Image Stat Files\n",
      "0:02:30.979460\n",
      "Mergeing Text Stat Files\n",
      "Finished Loading and Merging Image and Text Files\n",
      "0:02:35.561207\n",
      ":-) Train: 1503424  Super: 1503424\n"
     ]
    }
   ],
   "source": [
    "# Use the helper script\n",
    "import helper\n",
    "dfTrain, dfTest = helper.fn_LoadData(workDir + fileTrain, workDir + fileTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>desc_numNumericWords</th>\n",
       "      <th>desc_numUpperCaseWords</th>\n",
       "      <th>desc_avgImportantWordLength</th>\n",
       "      <th>desc_avgAllWordLength</th>\n",
       "      <th>desc_numSentences</th>\n",
       "      <th>desc_avgWordsPerSentence</th>\n",
       "      <th>desc_avgWordLengthPerSentence</th>\n",
       "      <th>blur_quality</th>\n",
       "      <th>image_whitespace</th>\n",
       "      <th>image_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>e00f8ff2eaf9</td>\n",
       "      <td>Sverdlovsk region</td>\n",
       "      <td>Ekaterinburg</td>\n",
       "      <td>Personal things</td>\n",
       "      <td>Goods for children and toys</td>\n",
       "      <td>Bed dress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kokobi (cocoon for sleep)</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>4.818182</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>39aeb48f0017</td>\n",
       "      <td>Samara Region</td>\n",
       "      <td>Samara</td>\n",
       "      <td>For home and cottages</td>\n",
       "      <td>Furniture and interior</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rack for Clothes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>good</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id             region          city  \\\n",
       "0  b912c3c6a6ad  e00f8ff2eaf9  Sverdlovsk region  Ekaterinburg   \n",
       "1  2dac0150717d  39aeb48f0017      Samara Region        Samara   \n",
       "\n",
       "    parent_category_name                category_name    param_1 param_2  \\\n",
       "0        Personal things  Goods for children and toys  Bed dress     NaN   \n",
       "1  For home and cottages       Furniture and interior      Other     NaN   \n",
       "\n",
       "  param_3                      title      ...      desc_numNumericWords  \\\n",
       "0     NaN  Kokobi (cocoon for sleep)      ...                         0   \n",
       "1     NaN           Rack for Clothes      ...                         0   \n",
       "\n",
       "   desc_numUpperCaseWords  desc_avgImportantWordLength desc_avgAllWordLength  \\\n",
       "0                       0                     6.666667              4.818182   \n",
       "1                       0                     6.000000              4.000000   \n",
       "\n",
       "  desc_numSentences desc_avgWordsPerSentence  desc_avgWordLengthPerSentence  \\\n",
       "0                 1                      6.0                       6.666667   \n",
       "1                 2                      2.5                       6.000000   \n",
       "\n",
       "   blur_quality image_whitespace image_present  \n",
       "0          good              0.0             1  \n",
       "1          good              0.0             1  \n",
       "\n",
       "[2 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>desc_numNumericWords</th>\n",
       "      <th>desc_numUpperCaseWords</th>\n",
       "      <th>desc_avgImportantWordLength</th>\n",
       "      <th>desc_avgAllWordLength</th>\n",
       "      <th>desc_numSentences</th>\n",
       "      <th>desc_avgWordsPerSentence</th>\n",
       "      <th>desc_avgWordLengthPerSentence</th>\n",
       "      <th>blur_quality</th>\n",
       "      <th>image_whitespace</th>\n",
       "      <th>image_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6544e41a8817</td>\n",
       "      <td>dbe73ad6e4b5</td>\n",
       "      <td>Volgograd region</td>\n",
       "      <td>Volgograd</td>\n",
       "      <td>Personal things</td>\n",
       "      <td>Children's clothing and footwear</td>\n",
       "      <td>For boys</td>\n",
       "      <td>Footwear</td>\n",
       "      <td>25</td>\n",
       "      <td>I'll give free of charge</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>average</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65b9484d670f</td>\n",
       "      <td>2e11806abe57</td>\n",
       "      <td>Sverdlovsk region</td>\n",
       "      <td>Lower Tour</td>\n",
       "      <td>Hobbies and Recreation</td>\n",
       "      <td>Bicycles</td>\n",
       "      <td>Road</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Selling a bicycle</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6.090909</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>6.111111</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id             region        city  \\\n",
       "0  6544e41a8817  dbe73ad6e4b5   Volgograd region   Volgograd   \n",
       "1  65b9484d670f  2e11806abe57  Sverdlovsk region  Lower Tour   \n",
       "\n",
       "     parent_category_name                     category_name   param_1  \\\n",
       "0         Personal things  Children's clothing and footwear  For boys   \n",
       "1  Hobbies and Recreation                          Bicycles      Road   \n",
       "\n",
       "    param_2 param_3                     title      ...       \\\n",
       "0  Footwear      25  I'll give free of charge      ...        \n",
       "1       NaN     NaN         Selling a bicycle      ...        \n",
       "\n",
       "  desc_numNumericWords  desc_numUpperCaseWords  desc_avgImportantWordLength  \\\n",
       "0                    0                       0                     4.500000   \n",
       "1                    0                       2                     6.090909   \n",
       "\n",
       "  desc_avgAllWordLength desc_numSentences desc_avgWordsPerSentence  \\\n",
       "0                  4.00                 1                 2.000000   \n",
       "1                  4.05                 3                 3.666667   \n",
       "\n",
       "   desc_avgWordLengthPerSentence blur_quality image_whitespace image_present  \n",
       "0                       4.500000      average              0.0             1  \n",
       "1                       6.111111                           NaN             0  \n",
       "\n",
       "[2 rows x 76 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert category features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category Name\n",
    "train_category_name_dummies = pd.get_dummies(dfTrain['category_name'])\n",
    "test_category_name_dummies = pd.get_dummies(dfTest['category_name'])\n",
    "\n",
    "# User Type\n",
    "train_user_type_dummies = pd.get_dummies(dfTrain['user_type'])\n",
    "test_user_type_dummies = pd.get_dummies(dfTest['user_type'])\n",
    "# train_city_dummies = pd.get_dummies(dfTrain['city']) # won't work\n",
    "\n",
    "# Region\n",
    "train_region_dummies = pd.get_dummies(dfTrain['region'])\n",
    "test_region_dummies = pd.get_dummies(dfTest['region'])\n",
    "\n",
    "# Parent Category Name\n",
    "train_parent_category_name_dummies = pd.get_dummies(dfTrain['parent_category_name'])\n",
    "test_parent_category_name_dummies = pd.get_dummies(dfTest['parent_category_name'])\n",
    "\n",
    "# Blur Quality\n",
    "train_blur_quality_dummies = pd.get_dummies(dfTrain['blur_quality'])\n",
    "test_blur_quality_dummies = pd.get_dummies(dfTest['blur_quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "# Running of different types of models\n",
    "\n",
    "# FIRST MODEL - \n",
    "trainModel1 = pd.concat([train_category_name_dummies, train_user_type_dummies], axis=1)\n",
    "testModel1 = pd.concat([test_category_name_dummies, test_user_type_dummies], axis=1)\n",
    "model1Variables = ['category_name','user_type']\n",
    "\n",
    "\n",
    "# SECOND MODEL\n",
    "# categoryname, usertype, city - bad rsme\n",
    "#newTrain = pd.concat([train_category_name_dummies, train_user_type_dummies, train_city_dummies, dfTrain[['deal_probability']]], axis=1)\n",
    "#newTest = pd.concat([test_category_name_dummies, test_user_type_dummies, test_city_dummies], axis=1)\n",
    "\n",
    "# Fourth MODEL - categoryname, usertype, price\n",
    "trainModel4 = pd.concat([train_category_name_dummies, train_user_type_dummies, dfTrain[['price']]], axis=1)\n",
    "testModel4 = pd.concat([test_category_name_dummies, test_user_type_dummies, dfTest['price']], axis=1)\n",
    "# Standardize the values\n",
    "model4Variables = ['category_name','user_type','price']\n",
    "\n",
    "# MODEL 5 - parent_category_name, usertype\n",
    "model5Variables = ['parent_category_name','user_type']\n",
    "trainModel5 = pd.concat([train_parent_category_name_dummies, train_user_type_dummies], axis=1)\n",
    "testModel5 = pd.concat([test_parent_category_name_dummies, test_user_type_dummies], axis=1)\n",
    "# Standardize the values\n",
    "\n",
    "\n",
    "# MODEL 6 - parent_category_name, usertype, price - not real improvement\n",
    "model6Variables = ['parent_category_name','user_type','price']\n",
    "trainModel6 = pd.concat([train_parent_category_name_dummies, train_user_type_dummies, dfTrain[['price']]], axis=1)\n",
    "testModel6 = pd.concat([test_parent_category_name_dummies, test_user_type_dummies, dfTest['price']], axis=1)\n",
    "# Standardize the values\n",
    "\n",
    "\n",
    "# Model 7 - lots of params\n",
    "model7Variables = ['category_name','user_type', 'price','price_mean','item_seq_number_mean']\n",
    "trainModel7 = pd.concat([train_category_name_dummies, train_user_type_dummies, dfTrain[['price','price_mean','item_seq_number_mean','deal_probability']]], axis=1)\n",
    "testModel7 = pd.concat([test_category_name_dummies, test_user_type_dummies, dfTest[['price','price_mean','item_seq_number_mean']]], axis=1)\n",
    "\n",
    "\n",
    "model8Variables = ['category_name', 'price','price_mean','item_seq_number_mean']\n",
    "trainModel8 = pd.concat([train_category_name_dummies, dfTrain[['price','price_mean','item_seq_number_mean','deal_probability']]], axis=1)\n",
    "testModel8 = pd.concat([test_category_name_dummies, dfTest[['price','price_mean','item_seq_number_mean']]], axis=1)\n",
    "\n",
    "# Model 9 - Include Text Features\n",
    "# desc_avgWordLengthPerSentence - Need to replace or impute\n",
    "# desc_wordsCondition - Need to analya\n",
    "textCols = ['desc_numWords','desc_numStopWords','desc_numNouns','desc_numVerbs','desc_numAdjs',\\\n",
    "'desc_numSymbols','desc_numNonASCIIWords','desc_numNumericWords','desc_numUpperCaseWords',\\\n",
    "'desc_avgImportantWordLength','desc_avgAllWordLength','desc_numSentences','desc_avgWordsPerSentence']\n",
    "\n",
    "model9Variables = ['category_name', 'user_type', 'text columns - minus 2']\n",
    "trainModel9 = pd.concat([train_category_name_dummies, train_user_type_dummies, \\\n",
    "                         dfTrain[textCols], dfTrain[['deal_probability']]], axis=1)\n",
    "testModel9 = pd.concat([test_category_name_dummies, test_user_type_dummies, \\\n",
    "                        dfTest[textCols]], axis=1)\n",
    "\n",
    "# Model10 - with some Image Features\n",
    "imageCols = ['clrchn_b_mean','clrchn_g_mean','clrchn_r_mean','blurColorScale','brightness','contrastColorScale']\n",
    "\n",
    "model10Variables = ['user_type', 'beginner image columns']\n",
    "trainModel10 = pd.concat([train_category_name_dummies, train_user_type_dummies, \\\n",
    "                         dfTrain[imageCols]], axis=1)\n",
    "testModel10 = pd.concat([test_category_name_dummies, test_user_type_dummies, \\\n",
    "                        dfTest[imageCols]], axis=1)\n",
    "\n",
    "\n",
    "# MODEL 11 - parent_category_name, usertype, price - not real improvement\n",
    "model11Variables = ['parent_category_name','user_type','price','textcol','imagecol']\n",
    "trainModel11 = pd.concat([train_parent_category_name_dummies, train_user_type_dummies, \\\n",
    "                          dfTrain[['price']], dfTrain[textCols], dfTrain[imageCols]], axis=1)\n",
    "testModel11 = pd.concat([test_parent_category_name_dummies, test_user_type_dummies, \\\n",
    "                         dfTest[['price']], dfTest[textCols], dfTest[imageCols]], axis=1)\n",
    "\n",
    "# MODEL 12 - Just Image + Text Features\n",
    "model12Variables = ['textCol','imagecol']\n",
    "trainModel12 = pd.concat([dfTrain[textCols], dfTrain[imageCols]], axis=1)\n",
    "testModel12 = pd.concat([dfTest[textCols], dfTest[imageCols]], axis=1)\n",
    "\n",
    "# MODEL 13 - \n",
    "model13Variables = ['contrast','brightness','blur']\n",
    "#textCols = ['contrastColorScale','brightness','blurColorScale']\n",
    "trainModel13 = pd.concat([dfTrain['region'], train_category_name_dummies, dfTrain[textCols], dfTrain[imageCols]], axis=1)\n",
    "testModel13 = pd.concat([dfTest['region'], test_category_name_dummies, dfTest[textCols], dfTest[imageCols]], axis=1)\n",
    "\n",
    "# MODEL 13 v2\n",
    "model13Variables = ['contrast','brightness','blur','price']\n",
    "imageCols = ['contrastColorScale','brightness','blurColorScale']\n",
    "trainModel13 = pd.concat([dfTrain['region'], train_parent_category_name_dummies, train_user_type_dummies, dfTrain[['contrastColorScale','brightness','blurColorScale','price']]], axis=1)\n",
    "testModel13 = pd.concat([dfTest['region'], test_parent_category_name_dummies, test_user_type_dummies, dfTest[['contrastColorScale','brightness','blurColorScale','price']]], axis=1)\n",
    "\n",
    "# NExt - just try withou the categories?  See which coefficients are brining down.\n",
    "# Or group by the category name, and then do the images + price\n",
    "model13Variables = ['brightness','blurColorScale']\n",
    "imageCols = ['brightness','blurColorScale']\n",
    "trainModel14 = pd.concat([train_user_type_dummies, dfTrain[imageCols]], axis=1)\n",
    "testModel14 = pd.concat([test_user_type_dummies, dfTest[imageCols]], axis=1)\n",
    "\n",
    "trainModel15 = pd.concat([train_parent_category_name_dummies, train_user_type_dummies, \\\n",
    "                          dfTrain[['desc_numVerbs','desc_numAdjs','desc_avgWordsPerSentence']]], axis=1)\n",
    "testModel15 = pd.concat([test_parent_category_name_dummies, test_user_type_dummies, \\\n",
    "                         dfTest[['desc_numVerbs','desc_numAdjs','desc_avgWordsPerSentence']]], axis=1)\n",
    "\n",
    "\n",
    "# NEXT ROUND - STARTING OVER\n",
    "trainModel20 = pd.concat([train_parent_category_name_dummies, train_category_name_dummies, train_user_type_dummies, \\\n",
    "                          dfTrain[['desc_numVerbs']]], axis=1)\n",
    "testModel20 = pd.concat([test_parent_category_name_dummies, test_category_name_dummies, test_user_type_dummies, \\\n",
    "                         dfTest[['desc_numVerbs']]], axis=1)\n",
    "model1Variables = ['category_name','user_type']\n",
    "\n",
    "# number of verbs + image white space\n",
    "trainModel21 = pd.concat([train_parent_category_name_dummies, train_category_name_dummies, train_user_type_dummies, train_blur_quality_dummies, \\\n",
    "                          dfTrain[['desc_numVerbs','image_whitespace','image_present']]], axis=1)\n",
    "testModel21 = pd.concat([test_parent_category_name_dummies, test_category_name_dummies, test_user_type_dummies, test_blur_quality_dummies, \\\n",
    "                         dfTest[['desc_numVerbs','image_whitespace','image_present']]], axis=1)\n",
    "\n",
    "trainModel22 = pd.concat([train_category_name_dummies, train_user_type_dummies, train_blur_quality_dummies, \\\n",
    "                          dfTrain[['image_whitespace','image_present']]], axis=1)\n",
    "testModel22 = pd.concat([test_category_name_dummies, test_user_type_dummies, test_blur_quality_dummies, \\\n",
    "                         dfTest[['image_whitespace','image_present']]], axis=1)\n",
    "\n",
    "trainModel = trainModel22\n",
    "testModel = testModel22\n",
    "bUseImages = 0\n",
    "bUseText= 0\n",
    "\n",
    "# Fill NA - in the future - fill with median\n",
    "trainModel.fillna(0, inplace=True)\n",
    "testModel.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Standardize the values - if we pull in something other than one-hot encoding\n",
    "scaleValues = 1\n",
    "if scaleValues == 1:\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range = (0, 1))\n",
    " \n",
    "    if bUseImages == 1:\n",
    "        trainModel[imageCols] = scaler.fit_transform(trainModel[imageCols])\n",
    "        testModel[imageCols] = scaler.fit_transform(testModel[imageCols])\n",
    "    if bUseText == 1:\n",
    "        trainModel[textCols] = scaler.fit_transform(trainModel[textCols])\n",
    "        testModel[textCols] = scaler.fit_transform(testModel[textCols])\n",
    "\n",
    "# Add the deal probability afterward - do not want to scale that\n",
    "trainModel = pd.concat([trainModel, dfTrain['deal_probability']], axis=1)\n",
    "\n",
    "\n",
    "# Here we are splitting two types of data sets \n",
    "# One built for binary classification models, and one without.\n",
    "# Auto-config the Binary dataset\n",
    "# copy\n",
    "trainModelBinary = trainModel.copy()\n",
    "# Drop probability\n",
    "trainModelBinary = trainModelBinary.drop('deal_probability',axis=1)\n",
    "# Add Deal Binary\n",
    "trainModelBinary = pd.concat([trainModelBinary, dfTrain[['deal_binary']]],axis=1)\n",
    "# Test stays the same\n",
    "testModelBinary = testModel\n",
    "\n",
    "# check for a mis-copy here when merging above\n",
    "if len(testModel) > 1000000 or len(testModelBinary) > 1000000:\n",
    "    print('!!! Bad Test Size !!! - Check concat variables')\n",
    "\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review Data (if need be)\n",
    "# trainModel.head(5)\n",
    "# testModel.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainModelBinary.head(5)\n",
    "# testModelBinary.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a base line - from the mean probability of the groups below\n",
    "Group by region, city, category_name, user_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mean_submission():\n",
    "\n",
    "    # 7,000 missing with this\n",
    "    groupColumnList = ['region','city','category_name','user_type']\n",
    "    joinColumns = ['region','city','category_name','user_type']\n",
    "\n",
    "    dfLevel1Mean = helper.fn_AddStatToDataframe(dfTrain, groupColumnList, 'deal_probability', 'mean')\n",
    "    dfTestMean = pd.merge(dfTest, dfLevel1Mean, how='left', on =joinColumns)\n",
    "\n",
    "    # 106 missing with this\n",
    "    groupColumnList = ['region','category_name','user_type']\n",
    "    joinColumns = ['region','category_name','user_type']\n",
    "\n",
    "    dfLevel2Mean = helper.fn_AddStatToDataframe(dfTrain, groupColumnList, 'deal_probability', 'mean')\n",
    "    dfLevel2Mean.rename(columns={'deal_probability_mean':'deal_probability_mean_l2'}, inplace=True)\n",
    "    dfTestMean = pd.merge(dfTestMean, dfLevel2Mean, how='left', on =joinColumns)\n",
    "\n",
    "\n",
    "    # 0 missing with this\n",
    "    groupColumnList = ['category_name','user_type']\n",
    "    joinColumns = ['category_name','user_type']\n",
    "\n",
    "    dfLevel3Mean = helper.fn_AddStatToDataframe(dfTrain, groupColumnList, 'deal_probability', 'mean')\n",
    "    dfLevel3Mean.rename(columns={'deal_probability_mean':'deal_probability_mean_l3'}, inplace=True)\n",
    "    dfTestMean = pd.merge(dfTestMean, dfLevel3Mean, how='left', on =joinColumns)\n",
    "\n",
    "\n",
    "    # Fill in for Level2, then for Level3\n",
    "    dfTestMean.loc[dfTestMean['deal_probability_mean'].isnull(), ('deal_probability_mean')] = dfTestMean['deal_probability_mean_l2']\n",
    "    dfTestMean.loc[dfTestMean['deal_probability_mean'].isnull(), ('deal_probability_mean')] = dfTestMean['deal_probability_mean_l3']\n",
    "\n",
    "    print('Number of null deal_probability: ' + str(np.count_nonzero(dfTestMean['deal_probability_mean'].isnull().values)))\n",
    "\n",
    "    dfTestMean = dfTestMean[['item_id','deal_probability_mean']].copy()\n",
    "    dfTestMean.rename(columns={'deal_probability_mean':'deal_probability'}, inplace=True)\n",
    "\n",
    "    # Export to csv\n",
    "    output_submission_file(dfTestMean, 'base')\n",
    "\n",
    "# when I generate\n",
    "# generate_mean_submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_model(model, binary, df, suppressMessages = False):\n",
    "  \n",
    "    if binary == False:\n",
    "        \n",
    "        # Split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df.drop('deal_probability',axis=1), \n",
    "                                                df['deal_probability'], test_size=0.30, \n",
    "                                                random_state=101)\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        modelPredictions = model.predict(X_test)\n",
    "    \n",
    "        # The mean squared error    \n",
    "        mae = mean_absolute_error(y_test, modelPredictions)\n",
    "        mse = np.round(mean_squared_error(y_test, modelPredictions), 4)\n",
    "        r2 = np.round(r2_score(y_test, modelPredictions), 4)\n",
    "        if suppressMessages == False:\n",
    "            print(\"Mean Abs error: %.2f\" % mae)\n",
    "            print(\"Mean squared error: %.2f\" % mse)\n",
    "            print('Variance (r2) score: %.2f' % r2)\n",
    "        \n",
    "        return mse, r2\n",
    " \n",
    "    elif binary == True:\n",
    "\n",
    "        # Split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df.drop('deal_binary',axis=1), \n",
    "                                                df['deal_binary'], test_size=0.30, \n",
    "                                                random_state=101)\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        modelPredictions = model.predict_proba(X_test)\n",
    "\n",
    "        # The mean squared error\n",
    "        mse0 = mean_squared_error(y_test, modelPredictions[:,:1])\n",
    "        var0 = r2_score(y_test, modelPredictions[:,:1])\n",
    "        #print(\"Mean Abs error: %.2f\" % mean_absolute_error(y_test, modelPredictions))\n",
    "        print(\"Mean squared error (0): %.2f\" % mse0)\n",
    "        print('Variance (r2) score (0): %.2f' % var0)\n",
    "\n",
    "        # Closer to 1\n",
    "        mse1 = mean_squared_error(y_test, modelPredictions[:,1:2])\n",
    "        var1 = r2_score(y_test, modelPredictions[:,1:2])\n",
    "        #print(\"Mean Abs error: %.2f\" % mean_absolute_error(y_test, modelPredictions))\n",
    "        print(\"Mean squared error (1): %.2f\" % mse1)\n",
    "        print('Variance (r2) score (1): %.2f' % var1) \n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================\n",
      "Linear Regression:\n",
      "Mean Abs error: 0.17\n",
      "Mean squared error: 0.06\n",
      "Variance (r2) score: 0.14\n",
      "===================\n",
      "Ridge Regression:\n",
      "Mean Abs error: 0.17\n",
      "Mean squared error: 0.06\n",
      "Variance (r2) score: 0.14\n",
      "===================\n",
      "Lasso Regression:\n",
      "Mean Abs error: 0.19\n",
      "Mean squared error: 0.07\n",
      "Variance (r2) score: -0.00\n",
      "===================\n",
      "ElasticNet Regression:\n",
      "Mean Abs error: 0.19\n",
      "Mean squared error: 0.07\n",
      "Variance (r2) score: -0.00\n",
      "===================\n",
      "Decision Tree Regressor:\n",
      "Mean Abs error: 0.17\n",
      "Mean squared error: 0.06\n",
      "Variance (r2) score: 0.13\n",
      "===================\n",
      "Random Forest Regressor:\n",
      "Mean Abs error: 0.17\n",
      "Mean squared error: 0.06\n",
      "Variance (r2) score: 0.14\n",
      "Mean Abs error: 0.18\n",
      "Mean squared error: 0.06\n",
      "Variance (r2) score: 0.07\n",
      "\n",
      "\n",
      "===================\n",
      "Logistic Regresion:\n",
      "Mean squared error (0): 0.47\n",
      "Variance (r2) score (0): -1.05\n",
      "Mean squared error (1): 0.18\n",
      "Variance (r2) score (1): 0.22\n",
      "===================\n",
      "RandomForestClassifier (depth 1):\n",
      "Mean squared error (0): 0.33\n",
      "Variance (r2) score (0): -0.45\n",
      "Mean squared error (1): 0.22\n",
      "Variance (r2) score (1): 0.05\n",
      "-------------------\n",
      "RandomForestClassifier (depth 2):\n",
      "Mean squared error (0): 0.33\n",
      "Variance (r2) score (0): -0.47\n",
      "Mean squared error (1): 0.21\n",
      "Variance (r2) score (1): 0.06\n",
      "-------------------\n",
      "RandomForestClassifier (depth 3):\n",
      "Mean squared error (0): 0.36\n",
      "Variance (r2) score (0): -0.58\n",
      "Mean squared error (1): 0.20\n",
      "Variance (r2) score (1): 0.12\n",
      "===================\n",
      "DecisionTreeClassifier:\n",
      "Mean squared error (0): 0.47\n",
      "Variance (r2) score (0): -1.07\n",
      "Mean squared error (1): 0.18\n",
      "Variance (r2) score (1): 0.23\n",
      "===================\n",
      "GaussianNB:\n",
      "Mean squared error (0): 0.72\n",
      "Variance (r2) score (0): -2.16\n",
      "Mean squared error (1): 0.27\n",
      "Variance (r2) score (1): -0.19\n",
      "===================\n",
      "Finsihed Running Models\n"
     ]
    }
   ],
   "source": [
    "# Run each of the models one at a time - kind of struggled to see which one woudl perform the best in this competition\n",
    "print('===================')\n",
    "print('Linear Regression:')\n",
    "run_test_model(linear_model.LinearRegression(), False, trainModel)\n",
    "print('===================')\n",
    "print('Ridge Regression:')\n",
    "run_test_model(Ridge(), False, trainModel)\n",
    "print('===================')\n",
    "print('Lasso Regression:')\n",
    "run_test_model(Lasso(), False, trainModel)\n",
    "print('===================')\n",
    "print('ElasticNet Regression:')\n",
    "run_test_model(ElasticNet(), False, trainModel)\n",
    "print('===================')\n",
    "print('Decision Tree Regressor:')\n",
    "run_test_model(DecisionTreeRegressor(max_depth=10), False, trainModel)\n",
    "print('===================')\n",
    "print('Random Forest Regressor:')\n",
    "run_test_model(RandomForestRegressor(), False, trainModel)\n",
    "run_test_model(RandomForestRegressor(max_depth=2, random_state=0), False, trainModel)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('===================')\n",
    "print('Logistic Regresion:')\n",
    "run_test_model(LogisticRegression(), True, trainModelBinary)\n",
    "print('===================')\n",
    "print('RandomForestClassifier (depth 1):')\n",
    "run_test_model(RandomForestClassifier(max_depth=1), True, trainModelBinary)\n",
    "print('-------------------')\n",
    "print('RandomForestClassifier (depth 2):')\n",
    "run_test_model(RandomForestClassifier(max_depth=2), True, trainModelBinary)\n",
    "print('-------------------')\n",
    "print('RandomForestClassifier (depth 3):')\n",
    "run_test_model(RandomForestClassifier(max_depth=3), True, trainModelBinary)\n",
    "\n",
    "\n",
    "\n",
    "print('===================')\n",
    "print('DecisionTreeClassifier:')\n",
    "run_test_model(DecisionTreeClassifier(), True, trainModelBinary)\n",
    "print('===================')\n",
    "print('GaussianNB:')\n",
    "run_test_model(GaussianNB(), True, trainModelBinary)\n",
    "print('===================')\n",
    "\n",
    "print('Finsihed Running Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a non-binary model\n",
    "def run_production_model_non_binary(model, model_name, binary, dfTr, dfTe, dfTestInput):\n",
    "        \n",
    "    # Split\n",
    "    X_train = dfTr.drop('deal_probability',axis=1)\n",
    "    y_train = dfTr['deal_probability']\n",
    "    X_test = dfTe\n",
    "    y_test = dfTe.index\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    modelPredictions = model.predict(X_test)\n",
    "\n",
    "    # Assign Predictions\n",
    "    X_test['deal_probability'] = modelPredictions\n",
    "\n",
    "    # Export item_id, deal_probability\n",
    "    finalOutputDF = pd.concat((dfTestInput[['item_id']], X_test[['deal_probability']]), axis=1)\n",
    "\n",
    "    # See how many need to be cleaned up\n",
    "    print('Num records less than 0: ' + str(len(finalOutputDF[finalOutputDF['deal_probability'] < 0])))\n",
    "\n",
    "    # Clean\n",
    "    finalOutputDF.loc[finalOutputDF['deal_probability'] < 0, 'deal_probability'] = 0\n",
    "\n",
    "    # Export to csv\n",
    "    output_submission_file(finalOutputDF, model_name)\n",
    "\n",
    "# Run a binary model\n",
    "def run_production_model_binary(model, model_name, binary, probabilityTowardsOne, dfTr, dfTe, dfTestInput):\n",
    "           \n",
    "    # Split\n",
    "    X_train = dfTr.drop('deal_binary',axis=1).copy()\n",
    "    y_train = dfTr['deal_binary'].copy()\n",
    "    X_test = dfTe.copy()\n",
    "    y_test = dfTe.index\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    # Assign Predictions\n",
    "    if probabilityTowardsOne == False:\n",
    "        modelPredictions = model.predict_proba(X_test)\n",
    "        X_test['deal_probability'] = modelPredictions[:,:1]\n",
    "    elif probabilityTowardsOne ==True:\n",
    "        modelPredictions = model.predict_proba(X_test)\n",
    "        X_test['deal_probability'] = modelPredictions[:,1:2]\n",
    "\n",
    "    # Export item_id, deal_probability\n",
    "    finalOutputDF = pd.concat((dfTestInput[['item_id']], X_test[['deal_probability']]), axis=1)\n",
    "\n",
    "    # See how many need to be cleaned up\n",
    "    print('Num records less than 0: ' + str(len(finalOutputDF[finalOutputDF['deal_probability'] < 0])))\n",
    "\n",
    "    # Clean\n",
    "    finalOutputDF.loc[finalOutputDF['deal_probability'] < 0, 'deal_probability'] = 0\n",
    "\n",
    "    # Export to csv\n",
    "    output_submission_file(finalOutputDF, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num records less than 0: 0\n"
     ]
    }
   ],
   "source": [
    "# Run different variations of the model\n",
    "\n",
    "#run_production_model_non_binary(linear_model.LinearRegression(), 'linReg', False, trainModel, testModel, dfTest)\n",
    "\n",
    "run_production_model_non_binary(RandomForestRegressor(), 'DecTreeReg', False, trainModel, testModel, dfTest)\n",
    "\n",
    "#run_production_model_binary(model=LogisticRegression(), model_name='LogReg',\\\n",
    "#                            binary=True, probabilityTowardsOne=True, \\\n",
    "#                            dfTr=trainModelBinary, dfTe=testModelBinary, dfTestInput=dfTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
