{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script will round up all the split result files and merge together them for a final submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory / files\n",
    "workDir = 'D:\\\\project\\\\data\\\\kg_corpgroc\\\\'\n",
    "eportDir = 'D:\\\\project\\\\data\\\\kg_corpgroc\\\\export\\\\completed\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test file\n",
    "testPD = pd.read_csv(workDir + 'test.csv')\n",
    "\n",
    "# submission file\n",
    "submissionPD = pd.read_csv(workDir + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for filename in glob.glob(workDir + '/*results*'):\n",
    "#    print (filename)\n",
    "    \n",
    "# get data file names\n",
    "#path =r'C:\\DRO\\DCL_rawdata_files'\n",
    "filenames = glob.glob(eportDir + '/*results*')    \n",
    "    \n",
    "dfs = []\n",
    "for filename in filenames:\n",
    "    dfs.append(pd.read_csv(filename))\n",
    "\n",
    "# Concatenate all data into one DataFrame\n",
    "big_frame = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expecting 3,370,464 rows\n",
    "#testPD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submissionPD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did not really need to index, missed the item_nbr on the join, \n",
    "#  but will keep in place anyway becuase it has perf benefits on the join\n",
    "testPD.set_index(['store_nbr','date','item_nbr'], inplace=True)\n",
    "big_frame.set_index(['store_nbr','date','item_nbr'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join taking the tesPD as the main\n",
    "joinDF = pd.merge(testPD, big_frame, how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functino to set any negative values to 0 as they are not allowed for submission\n",
    "def fn_set_negative_to_zero(col):\n",
    "    if col < 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to write the submission file\n",
    "# Sometime the input column name would be the log version, or the moving average value, so it gets re-named \n",
    "#  to the standard \"visitors\" expected by the competition\n",
    "def fn_write_submission_file(df, colNames, fileName):\n",
    "    \n",
    "    print(colNames[1])\n",
    "    forecastCol = colNames[1]\n",
    "    \n",
    "    tempDF = df.copy()\n",
    "    \n",
    "    # Rename the second column to \"visitors\" as per submission\n",
    "    tempDF.rename(columns={forecastCol: 'unit_sales'}, inplace=True)\n",
    "    \n",
    "    #print(tempDF.head())\n",
    "    tempDF.to_csv(fileName, header=True, index=False, quotechar='\"', columns=('id','unit_sales'))\n",
    "    print('Wrote file: ' + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "dfFinal = joinDF.copy()\n",
    "\n",
    "# re-name varaibles - Actually just keep only columns that we need\n",
    "dfFinal = dfFinal[['id_x','forecast','forecast_rnd']]\n",
    "dfFinal.rename(columns={'id_x': 'id'}, inplace=True)\n",
    "\n",
    "# set any nan to 0.  Some of the test items do not have entries in each store, so it would error/skip during generation.\n",
    "#  here I am setting to 0, instead of trying to model/guess a new item being add that never existed or has not\n",
    "#  been stocked in the past 365 days.\n",
    "dfFinal['forecast'] = dfFinal['forecast'].replace(np.nan, 0)\n",
    "dfFinal['forecast_rnd'] = dfFinal['forecast_rnd'].replace(np.nan, 0)\n",
    "\n",
    "# set any negative to 0\n",
    "dfFinal['forecast'] = dfFinal.apply(lambda row: fn_set_negative_to_zero(row['forecast']), axis=1)\n",
    "dfFinal['forecast_rnd'] = dfFinal.apply(lambda row: fn_set_negative_to_zero(row['forecast_rnd']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfFinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecast\n",
      "Wrote file: D:\\project\\data\\kg_corpgroc\\20180105_subm_frcst_flt.csv\n",
      "forecast_rnd\n",
      "Wrote file: D:\\project\\data\\kg_corpgroc\\20180105_subm_frcst_rnd.csv\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "todayDate = str(dt.date.today().strftime('%Y%m%d'))\n",
    "exportDir = 'D:\\\\project\\\\data\\\\kg_corpgroc\\\\'\n",
    "\n",
    "# Float forecast submission\n",
    "columns=('id','forecast')\n",
    "fn_write_submission_file(dfFinal, columns, exportDir + todayDate + '_subm_frcst_flt.csv')\n",
    "\n",
    "# Rounded Forecast submission\n",
    "columns=('id','forecast_rnd')\n",
    "fn_write_submission_file(dfFinal, columns, exportDir + todayDate + '_subm_frcst_rnd.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
