{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT OFF:  Need to split the models.  1 for items with age of well.  1 without."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# DECISION TREE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# RANDOM FORREST\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mac\n",
    "# workdir = '/Project/data/dd_WaterTable/'\n",
    "# windows\n",
    "workdir = 'D:\\\\project\\\\data\\\\dd_watertable\\\\'\n",
    "file_train_data = 'training_data.csv'\n",
    "file_train_label = 'training_label.csv'\n",
    "file_test_data = 'test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN - ALSO RESTARTING POINT BEFORE MASSAGING, FETURES, DUMMY CODES\n",
    "df_train_data = pd.read_csv(workdir + file_train_data)\n",
    "df_train_label = pd.read_csv(workdir + file_train_label)\n",
    "df_test_data = pd.read_csv(workdir + file_test_data)\n",
    "\n",
    "# Merge the train data with the ID\n",
    "df_train_data = pd.merge(df_train_data, df_train_label, on ='id')\n",
    "\n",
    "\n",
    "# COLUMN DATA TYPE MASSAGING\n",
    "#  TODO: If time permits - find a more elgant way to code\n",
    "\n",
    "#------------------\n",
    "# DATE RECORDED\n",
    "#------------------\n",
    "df_train_data['date_recorded'] = df_train_data['date_recorded'].astype('datetime64[ns]')\n",
    "df_test_data['date_recorded'] = df_test_data['date_recorded'].astype('datetime64[ns]')\n",
    "\n",
    "#------------------\n",
    "# CONSTRUCTION YEAR\n",
    "#------------------\n",
    "# Convert to a string - Had issues with keeping as a int (converting over to float)\n",
    "# not the cleanest work-around, but works\n",
    "df_train_data['construction_year'] = df_train_data['construction_year'].astype(str)\n",
    "\n",
    "# Set this to June 1 (chnged to 1-1 becuase of negative vlues)\n",
    "# TODO: Go back and make this more intelligent.\n",
    "df_train_data.loc[df_train_data['construction_year'] != '0','construction_year'] = (df_train_data['construction_year'] + '-01-01') #.astype('datetime64[ns]')\n",
    "\n",
    "# if equal to 0 set to np.nan\n",
    "df_train_data.loc[df_train_data['construction_year'] == '0','construction_year'] = ''\n",
    "\n",
    "# convert to datetime\n",
    "df_train_data['construction_year'] = df_train_data['construction_year'].astype('datetime64[ns]')\n",
    "\n",
    "# Test data\n",
    "df_test_data['construction_year'] = df_test_data['construction_year'].astype(str)\n",
    "df_test_data.loc[df_test_data['construction_year'] != '0','construction_year'] = (df_test_data['construction_year'] + '-01-01') #.astype('datetime64[ns]')\n",
    "df_test_data.loc[df_test_data['construction_year'] == '0','construction_year'] = ''\n",
    "df_test_data['construction_year'] = df_test_data['construction_year'].astype('datetime64[ns]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# FEATURE ENGINEERING - Run first before dummy codes\n",
    "#####################\n",
    "from datetime import datetime\n",
    "\n",
    "# function to determine how old the well is (months)\n",
    "def func_ft_diff_month(cols):\n",
    "    d1 = cols[0]\n",
    "    d2 = cols[1]\n",
    "    \n",
    "    if d1 == np.datetime64('NaT') or d2 == np.datetime64('NaT'):\n",
    "        return 0\n",
    "    else:\n",
    "        return (d1.year - d2.year) * 12 + d1.month - d2.month\n",
    "\n",
    "# Build feature\n",
    "df_train_data['ft_monthsSinceBuild'] = df_train_data[['date_recorded','construction_year']].apply(func_ft_diff_month,axis=1)\n",
    "df_test_data['ft_monthsSinceBuild'] = df_test_data[['date_recorded','construction_year']].apply(func_ft_diff_month,axis=1)\n",
    "\n",
    "# Averge the rest?? - 34% -- Perhaps break this out into additional features\n",
    "df_train_data[df_train_data['ft_monthsSinceBuild']==np.NaN]['ft_monthsSinceBuild'] = df_train_data['ft_monthsSinceBuild'].mean()\n",
    "df_test_data[df_test_data['ft_monthsSinceBuild']==np.NaN]['ft_monthsSinceBuild'] = df_test_data['ft_monthsSinceBuild'].mean()\n",
    "\n",
    "\n",
    "# Fill in the months since the build with an average (or other)\n",
    "# when time permits- split this out into a feature\n",
    "train_ftMnths_mean = df_train_data['ft_monthsSinceBuild'].mean()\n",
    "test_ftMnths_mean = df_test_data['ft_monthsSinceBuild'].mean()\n",
    "\n",
    "df_train_data['ft_monthsSinceBuild'].replace({np.nan: train_ftMnths_mean}, inplace=True)\n",
    "df_test_data['ft_monthsSinceBuild'].replace({np.nan: test_ftMnths_mean}, inplace=True)\n",
    "# or replace with 12 or 0 (at least one year or nothing)\n",
    "#df_train_data['ft_monthsSinceBuild'].replace({np.nan: 12}, inplace=True)\n",
    "#df_test_data['ft_monthsSinceBuild'].replace({np.nan: 12}, inplace=True)\n",
    "\n",
    "# Bucket the Population sizes\n",
    "def func_ft_PopSizeEst(cols):\n",
    "    popSize = cols[0].astype('int64')\n",
    "    \n",
    "    if popSize == 0:\n",
    "        return 'ft_PopSize_Unknown'\n",
    "    if (popSize >= 0 and popSize < 50):\n",
    "        return 'ft_PopSize_Small'\n",
    "    if (popSize >= 50 and popSize < 100):\n",
    "        return 'ft_PopSize_Medium'\n",
    "    if popSize > 100 and popSize < 500:\n",
    "        return 'ft_PopSize_Large'\n",
    "    if popSize >= 500:\n",
    "        return 'ft_PopSize_ExtraLarge'\n",
    "    \n",
    "# Population\n",
    "df_train_data['ft_PopSizeEst'] = df_train_data[['population']].apply(func_ft_PopSizeEst, axis=1)\n",
    "df_test_data['ft_PopSizeEst'] = df_test_data[['population']].apply(func_ft_PopSizeEst, axis=1)\n",
    "\n",
    "# Handle for scheme management of None, can set this to NA\n",
    "#df_train_data[['scheme_management']=='None']['']\n",
    "df_train_data['scheme_management'].replace({'None': np.nan}, inplace=True)\n",
    "\n",
    "# Convert the construction year to a year, as model must use a float/num\n",
    "#construction_year\n",
    "\n",
    "# verified\n",
    "#df_train_data[['population','ft_PopSizeEst']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## CREATE DUMMY CODES\n",
    "\n",
    "**!! The List variables in this section control which variables we are using !! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do each one in a consolidated\n",
    "def convert_dummy_vars(dataFrame, columnName, dropFirst=False, colRename=''):\n",
    "    \n",
    "    temp = pd.get_dummies(dataFrame[columnName], drop_first=dropFirst)\n",
    "    \n",
    "    if colRename != '':\n",
    "        temp.columns = [(colRename)]\n",
    "    \n",
    "    dataFrame.drop([columnName], axis=1, inplace=True)\n",
    "    dataFrame = pd.concat([dataFrame, temp], axis=1)    \n",
    "    return dataFrame\n",
    "\n",
    "def fn_add_dummy_variables(df_feat_train, df_feat_test):\n",
    "\n",
    "    # Template\n",
    "    #for column in df:\n",
    "    #    print(df[column])\n",
    "\n",
    "    # Next loop through all columns to convert to dummy variables\n",
    "    for column in df_feat_train:\n",
    "\n",
    "        if column == 'ft_monthsSinceBuild' or column=='construction_year':\n",
    "            # do nothing - skip\n",
    "            a = 'skip'\n",
    "\n",
    "        elif column == 'public_meeting':\n",
    "            # special case\n",
    "            df_feat_train = convert_dummy_vars(dataFrame=df_feat_train, columnName='public_meeting', dropFirst=True, colRename='public_meeting_True')\n",
    "        else:\n",
    "            df_feat_train = convert_dummy_vars(df_feat_train, column)\n",
    "\n",
    "        # print(df_feat_train.shape)\n",
    "\n",
    "    print('\\n')\n",
    "    print('Test Shapes')\n",
    "\n",
    "    for column in df_feat_test:\n",
    "\n",
    "        if column == 'ft_monthsSinceBuild' or column=='construction_year':\n",
    "            # do nothing - skip\n",
    "            a = 'skip'\n",
    "\n",
    "        elif column == 'public_meeting':\n",
    "            # special case\n",
    "            df_feat_test = convert_dummy_vars(dataFrame=df_feat_test, columnName='public_meeting', dropFirst=True, colRename='public_meeting_True')\n",
    "        else:\n",
    "            df_feat_test = convert_dummy_vars(df_feat_test, column)\n",
    "\n",
    "    print('Train Cols: ' + str(len(df_feat_train.columns)) + '  Test Cols: ' + str(len(df_feat_test.columns)))\n",
    "            \n",
    "    return df_feat_train, df_feat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test Shapes\n",
      "Train Cols: 116  Test Cols: 116\n"
     ]
    }
   ],
   "source": [
    "# CHOOSE WHICH FEATURES TO INCLUDE\n",
    "# 'amount_tsh', - leave out - add after binning and plotting\n",
    "shortList_vTF = ['ft_monthsSinceBuild'] # 'ft_PopSizeEst',\n",
    "\n",
    "\n",
    "shortList_v1 = ['public_meeting','quantity','payment','waterpoint_type','source_class']\n",
    "shortList_v2 = ['public_meeting','quantity','payment','waterpoint_type','source_class','ft_PopSizeEst','ft_monthsSinceBuild']\n",
    "\n",
    "# Need to creat columns to OMIT\n",
    "\n",
    "# gps_height\n",
    "# 'construction_year',\n",
    "LongList_v1 = ['basin','district_code','public_meeting','scheme_management',\n",
    "                'extraction_type_class','management','payment','quantity','source','waterpoint_type','source_class',\n",
    "             'ft_monthsSinceBuild','ft_PopSizeEst']\n",
    "\n",
    "# swap out source_class with source + add region\n",
    "# 'construction_year',\n",
    "LongList_v2 = ['basin','district_code','public_meeting','scheme_management',\n",
    "                'extraction_type_class','management','payment','quantity','source','waterpoint_type','region', \\\n",
    "               'ft_monthsSinceBuild','ft_PopSizeEst']\n",
    "\n",
    "# Add source class\n",
    "# 'construction_year',\n",
    "LongList_v3 = ['basin','district_code','public_meeting','scheme_management',\n",
    "                'extraction_type_class','management','payment','quantity','source','waterpoint_type','source_class','region', \\\n",
    "               'ft_monthsSinceBuild','ft_PopSizeEst']\n",
    "\n",
    "LongList_v4 = LongList_v3 + ['permit']\n",
    "\n",
    "# Items to try\n",
    "# construction_year - took out - would have to convert to year int, about the same becuase I am using ft_months since build\n",
    "\n",
    "\n",
    "\n",
    "# Choose which feature list we are working with\n",
    "df_feat_train = df_train_data[LongList_v2]\n",
    "df_feat_test = df_test_data[LongList_v2]\n",
    "\n",
    "# Convert to dummy variables\n",
    "df_feat_train, df_feat_test = fn_add_dummy_variables(df_feat_train, df_feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_feat_train.rename(columns={\"True\":'public_meeting'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_feat_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feat_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the existing columns\n",
    "# df_feat_train.drop(['public_meeting','quantity','payment','waterpoint_type','source_class'], axis=1, inplace=True)\n",
    "# df_feat_train = pd.concat([df_feat_train,public_meeting, quantity, payment, waterpoint_type, source_class], axis=1)\n",
    "\n",
    "# df_feat_test.drop(['public_meeting','quantity','payment','waterpoint_type','source_class'], axis=1, inplace=True)\n",
    "# df_feat_test = pd.concat([df_feat_test,test_public_meeting, test_quantity, test_payment, test_waterpoint_type, test_source_class], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feat_train.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feat_test.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a SVM\n",
    "runSVMModel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "# LOCAL SPLIT\n",
    "##############\n",
    "\n",
    "if runSVMModel == True:\n",
    "    X = df_feat_train\n",
    "    y = df_train_label['status_group']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=101)\n",
    "\n",
    "    model = SVC()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Print Predictions\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# let's try with a different parameter\n",
    "######################################\n",
    "\n",
    "if runSVMModel == True:\n",
    "    bParamSearch = 0\n",
    "\n",
    "    if (bParamSearch == 1):\n",
    "        param_grid = {'C':[0.1,1,10,100,1000], 'gamma':[1,0.1,0.01,0.001,0.0001]}\n",
    "        grid = GridSearchCV(SVC(), param_grid, verbose=3)\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "        # best parameter\n",
    "        # {'C': 0.1, 'gamma': 1}\n",
    "        grid.best_params_\n",
    "\n",
    "        grid.best_estimator_\n",
    "        grid_predictions = grid.predict(X_test)\n",
    "\n",
    "    # Recheck everything\n",
    "    if (bParamSearch == 1):\n",
    "        print(confusion_matrix(y_test, grid_predictions))\n",
    "        print('\\n')\n",
    "        print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# WITH FULL RUN \n",
    "####################################\n",
    "\n",
    "if runSVMModel == True:\n",
    "    # X = df_feat_train\n",
    "    # y = df_train_label['status_group']\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=101)\n",
    "\n",
    "    X_train = df_feat_train\n",
    "    y_train = df_train_label['status_group']\n",
    "    X_test = df_feat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best parameter - if we flag to do so\n",
    "if runSVMModel == True:\n",
    "    bFindProdParmeter = 0\n",
    "    if bFindProdParmeter == 1:\n",
    "        param_grid = {'C':[0.1,1,10,100,1000], 'gamma':[1,0.1,0.01,0.001,0.0001]}\n",
    "        grid = GridSearchCV(SVC(), param_grid, verbose=3,n_jobs=6)\n",
    "        grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we are seraching for best parameter, then print it (to keep the verbose logging above separate)\n",
    "\n",
    "if runSVMModel == True:\n",
    "    if bFindProdParmeter == 1:\n",
    "        print(grid.best_params_)\n",
    "        # {'C': 0.1, 'gamma': 1}\n",
    "        # {'gamma': 0.1, 'C': 10}  - shortlist2\n",
    "        print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runSVMModel == True:\n",
    "    # shortlist\n",
    "    # {'C': 0.1, 'gamma': 1}\n",
    "    # .7162\n",
    "\n",
    "    # shortlist2\n",
    "    # {'gamma': 0.1, 'C': 10}  \n",
    "\n",
    "    # start tracking Time\n",
    "    print('Starting Model Run')\n",
    "    startTime = datetime.now()\n",
    "\n",
    "    ###################################\n",
    "    # RUN THE MODEL\n",
    "    model = SVC(C=10, gamma=0.1)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    ###################################\n",
    "\n",
    "    print ('Time to Finish: ' + str(datetime.now() - startTime)) \n",
    "\n",
    "    df_predictions = pd.DataFrame(predictions)\n",
    "    df_predictions.columns=['status_group']\n",
    "\n",
    "    # TODO: Need to add a date/time stamp and record what each model does\n",
    "    # df_final = pd.merge(df_predictions, df_test_data, on='index')\n",
    "    df_final = pd.concat([df_predictions, df_test_data], axis=1)[['id','status_group']]\n",
    "    df_final.set_index('id', inplace=True)\n",
    "    export_file = workdir + 'submission.csv'\n",
    "    df_final.to_csv(export_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runDecisionTreeModel = False\n",
    "if runDecisionTreeModel == True:\n",
    "    # Choose which feature list we are working with\n",
    "    df_feat_train = df_train_data[LongList_v4]\n",
    "    df_feat_test = df_test_data[LongList_v4]\n",
    "\n",
    "    # Convert to dummy variables\n",
    "    df_feat_train, df_feat_test = fn_add_dummy_variables(df_feat_train, df_feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LongList_v3 - 78, 43, 79 + 85, 33, 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runDecisionTreeModel == True:\n",
    "    print('Starting Model Run')\n",
    "    startTime = datetime.now()\n",
    "\n",
    "    X = df_feat_train\n",
    "    y = df_train_label['status_group']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=101)\n",
    "\n",
    "    dtree = DecisionTreeClassifier()\n",
    "    dtree.fit(X_train, y_train)\n",
    "    predictions = dtree.predict(X_test)\n",
    "\n",
    "    print ('Time to Finish: ' + str(datetime.now() - startTime)) \n",
    "\n",
    "    # Print Predictions\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Production\n",
    "if runDecisionTreeModel == True:\n",
    "    X_train = df_feat_train\n",
    "    y_train = df_train_label['status_group']\n",
    "    X_test = df_feat_test\n",
    "\n",
    "    dtree = DecisionTreeClassifier()\n",
    "    dtree.fit(X_train, y_train)\n",
    "    predictions = dtree.predict(X_test)\n",
    "\n",
    "    df_predictions = pd.DataFrame(predictions)\n",
    "    df_predictions.columns=['status_group']\n",
    "\n",
    "    # TODO: Need to add a date/time stamp and record what each model does\n",
    "    # df_final = pd.merge(df_predictions, df_test_data, on='index')\n",
    "    df_final = pd.concat([df_predictions, df_test_data], axis=1)[['id','status_group']]\n",
    "    df_final.set_index('id', inplace=True)\n",
    "    export_file = workdir + 'submission.csv'\n",
    "    df_final.to_csv(export_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runRandomForest = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runRandomForest==True:\n",
    "    # Choose which feature list we are working with\n",
    "    df_feat_train = df_train_data[LongList_v4]\n",
    "    df_feat_test = df_test_data[LongList_v4]\n",
    "\n",
    "    # Convert to dummy variables\n",
    "    df_feat_train, df_feat_test = fn_add_dummy_variables(df_feat_train, df_feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runRandomForest==True:\n",
    "    # 78, 60, 82 - with Long_v1\n",
    "    # 78, 60, 82 - with Long_v2\n",
    "    # 78, 60, 82 - with Long_v3\n",
    "    # 78, 62, 82 - with Long_v4\n",
    "\n",
    "    #######\n",
    "    # TEST \n",
    "    #######\n",
    "    X = df_feat_train\n",
    "    y = df_train_label['status_group']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=101)\n",
    "\n",
    "    #rfc = RandomForestClassifier(n_estimators=200)\n",
    "    #rfc = RandomForestClassifier(n_estimators=400, min_samples_split=10)\n",
    "    rfc = RandomForestClassifier(n_estimators=400, min_samples_split=10)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    predictions = rfc.predict(X_test)\n",
    "\n",
    "    # Print Predictions\n",
    "    print(confusion_matrix(y_test, predictions))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# Run Production\n",
    "#################\n",
    "if runRandomForest==True:\n",
    "    X_train = df_feat_train\n",
    "    y_train = df_train_label['status_group']\n",
    "    X_test = df_feat_test\n",
    "\n",
    "    #rfc = RandomForestClassifier(n_estimators=200)\n",
    "    rfc = RandomForestClassifier(n_estimators=400, min_samples_split=10)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    predictions = rfc.predict(X_test)\n",
    "\n",
    "    df_predictions = pd.DataFrame(predictions)\n",
    "    df_predictions.columns=['status_group']\n",
    "\n",
    "    # TODO: Need to add a date/time stamp and record what each model does\n",
    "    # df_final = pd.merge(df_predictions, df_test_data, on='index')\n",
    "    df_final = pd.concat([df_predictions, df_test_data], axis=1)[['id','status_group']]\n",
    "    df_final.set_index('id', inplace=True)\n",
    "    export_file = workdir + 'submission.csv'\n",
    "    df_final.to_csv(export_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
