{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "import platform\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "import warnings\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warnings.filterwarnings(\"ignore\") # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Dir / Load Data\n",
    "from sys import platform\n",
    "# if platform.system() == 'Windows':\n",
    "if platform == 'win32':\n",
    "    directory = 'D:\\\\project\\\\data\\\\kg_jpn_rest\\\\'\n",
    "    exportDirectory = directory + 'export\\\\'\n",
    "\n",
    "# Mac\n",
    "#elif platform.system() == 'Darwin':\n",
    "elif platform == 'darwin':\n",
    "    directory = '//Project/data/kg_corpgroc/'\n",
    "    exportDirectory = directory + 'export/'\n",
    "\n",
    "# AWS\n",
    "elif platform == 'linux':\n",
    "    directory = '//data/'\n",
    "    exportDirectory = directory + 'export/'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_CONST_DEBUG = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to load other notebooks to access.  Code to laod notebooks borrowed from online\n",
    "# http://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Importing%20Notebooks.html\n",
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        \n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "    \n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "        \n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "                                       \n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "        \n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "        \n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "        \n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "    \n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]   \n",
    "    \n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import after we find in the directory above\n",
    "import helper_notebook as hlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  moved this into the helper script (below) to pull from there and make enhancements\n",
    "\n",
    "# reservations in the air system\n",
    "pd_air_reserve = pd.read_csv(directory + 'air_reserve.csv', parse_dates=(['visit_datetime','reserve_datetime']), infer_datetime_format=True)\n",
    "pd_air_reserve.name = 'pd_air_reserve'\n",
    "#•\tair_store_id - the restaurant's id in the air system\n",
    "#•\tvisit_datetime - the time of the reservation\n",
    "#•\treserve_datetime - the time the reservation was made\n",
    "#•\treserve_visitors - the number of visitors for that reservation\n",
    "\n",
    "# reservation in the hpg system\n",
    "pd_hpg_reserve = pd.read_csv(directory + 'hpg_reserve.csv', parse_dates=(['visit_datetime','reserve_datetime']), infer_datetime_format=True)\n",
    "pd_hpg_reserve.name = 'pd_hpg_reserve'\n",
    "#•\thpg_store_id - the restaurant's id in the hpg system\n",
    "#•\tvisit_datetime - the time of the reservation\n",
    "#•\treserve_datetime - the time the reservation was made\n",
    "#•\treserve_visitors - the number of visitors for that reservation\n",
    "\n",
    "# contains info about the store info.  lat and long is the area which the store belongs\n",
    "pd_air_store_info = pd.read_csv(directory + 'air_store_info.csv', infer_datetime_format=True)\n",
    "pd_air_store_info.name = 'pd_air_store_info'\n",
    "#•\tair_store_id\n",
    "#•\tair_genre_name\n",
    "#•\tair_area_name\n",
    "#•\tlatitude\n",
    "#•\tlongitude\n",
    "\n",
    "# contains info about select air restaraunts.  Lat and long is the area where store belongs\n",
    "pd_hpg_store_info = pd.read_csv(directory + 'hpg_store_info.csv', infer_datetime_format=True)\n",
    "pd_hpg_store_info.name = 'pd_hpg_store_info'\n",
    "#•\thpg_store_id\n",
    "#•\thpg_genre_name\n",
    "#•\thpg_area_name\n",
    "#•\tlatitude\n",
    "#•\tlongitude\n",
    "\n",
    "# file contains HISTORICAL visit data for the air restaraunts\n",
    "pd_air_visit_data = pd.read_csv(directory + 'air_visit_data.csv', parse_dates=(['visit_date']), infer_datetime_format=True)\n",
    "pd_air_visit_data.name = 'pd_air_visit_data'\n",
    "#•\tair_store_id\n",
    "#•\tvisit_date - the date\n",
    "#•\tvisitors - the number of visitors to the restaurant on the date\n",
    "\n",
    "# give basic info about the calendar dates in the dataset\n",
    "pd_date_info = pd.read_csv(directory + 'date_info.csv', parse_dates=(['calendar_date']), infer_datetime_format=True)\n",
    "pd_date_info.name = 'pd_date_info'\n",
    "\n",
    "# allows you to join select restaraunts that have both air and hpg systems\n",
    "pd_store_id_relation = pd.read_csv(directory + 'store_id_relation.csv', infer_datetime_format=True)\n",
    "pd_store_id_relation.name = 'pd_store_id_relation'\n",
    "#•\thpg_store_id\n",
    "#•\tair_store_id\n",
    "'''\n",
    "\n",
    "# Still need to keep this for all the specific restaraunts they want submitted\n",
    "pd_sample_submission = pd.read_csv(directory + 'sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Load - Loading data on: Windows Directory: D:\\project\\data\\kg_jpn_rest\\\n",
      "0:00:11.475926\n",
      "Data Load - Merging Data\n",
      "0:01:09.758835\n",
      "Data Load - Adding Features\n",
      "0:01:24.464681\n",
      "Data Load - Finished\n"
     ]
    }
   ],
   "source": [
    "# Load the data set / cleaned, joined, and formatted\n",
    "dfSuper = hlp.fn_load_all_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 252108 entries, 2016-01-13 to 2017-04-22\n",
      "Data columns (total 48 columns):\n",
      "air_store_id        252108 non-null object\n",
      "visitors            252108 non-null float32\n",
      "calendar_date       252108 non-null datetime64[ns]\n",
      "day_of_week         252108 non-null object\n",
      "holiday_flg         252108 non-null int64\n",
      "genre_name\t         252108 non-null object\n",
      "area_name           252108 non-null object\n",
      "latitude            252108 non-null float64\n",
      "longitude           252108 non-null float64\n",
      "reserve_visitors    252108 non-null float64\n",
      "month_num           252108 non-null int64\n",
      "month_name          252108 non-null object\n",
      "dayofmonth_num      252108 non-null int64\n",
      "dayofweek_num       252108 non-null int64\n",
      "weekend             252108 non-null int64\n",
      "corr_vis_resv       252108 non-null float64\n",
      "cycle               252108 non-null float64\n",
      "trend               252108 non-null float64\n",
      "SMA_3_days          252108 non-null float64\n",
      "SMA_7_days          252108 non-null float64\n",
      "SMA_14_days         252108 non-null float64\n",
      "SMA_30_days         252108 non-null float64\n",
      "SMA_90_days         252108 non-null float64\n",
      "EWMA_3_days         252108 non-null float64\n",
      "EWMA_7_days         252108 non-null float64\n",
      "EWMA_14_days        252108 non-null float64\n",
      "EWMA_30_days        252108 non-null float64\n",
      "EWMA_90_days        252108 non-null float64\n",
      "Friday              252108 non-null uint8\n",
      "Monday              252108 non-null uint8\n",
      "Saturday            252108 non-null uint8\n",
      "Sunday              252108 non-null uint8\n",
      "Thursday            252108 non-null uint8\n",
      "Tuesday             252108 non-null uint8\n",
      "Wednesday           252108 non-null uint8\n",
      "Apr                 252108 non-null uint8\n",
      "Aug                 252108 non-null uint8\n",
      "Dec                 252108 non-null uint8\n",
      "Feb                 252108 non-null uint8\n",
      "Jan                 252108 non-null uint8\n",
      "Jul                 252108 non-null uint8\n",
      "Jun                 252108 non-null uint8\n",
      "Mar                 252108 non-null uint8\n",
      "May                 252108 non-null uint8\n",
      "Nov                 252108 non-null uint8\n",
      "Oct                 252108 non-null uint8\n",
      "Sep                 252108 non-null uint8\n",
      "forecast            252108 non-null float32\n",
      "dtypes: datetime64[ns](1), float32(2), float64(16), int64(5), object(5), uint8(19)\n",
      "memory usage: 60.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dfSuper.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>calendar_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>genre_name</th>\n",
       "      <th>area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>...</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Mar</th>\n",
       "      <th>May</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Sep</th>\n",
       "      <th>forecast</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-13</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-14</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-15</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-16</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-18</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_store_id  visitors calendar_date day_of_week  \\\n",
       "visit_date                                                             \n",
       "2016-01-13  air_ba937bf13d40fb24      25.0    2016-01-13   Wednesday   \n",
       "2016-01-14  air_ba937bf13d40fb24      32.0    2016-01-14    Thursday   \n",
       "2016-01-15  air_ba937bf13d40fb24      29.0    2016-01-15      Friday   \n",
       "2016-01-16  air_ba937bf13d40fb24      22.0    2016-01-16    Saturday   \n",
       "2016-01-18  air_ba937bf13d40fb24       6.0    2016-01-18      Monday   \n",
       "\n",
       "            holiday_flg genre_name\\t                     area_name   latitude  \\\n",
       "visit_date                                                                      \n",
       "2016-01-13            0   Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "2016-01-14            0   Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "2016-01-15            0   Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "2016-01-16            0   Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "2016-01-18            0   Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "\n",
       "             longitude  reserve_visitors    ...     Feb Jan  Jul  Jun  Mar  \\\n",
       "visit_date                                  ...                              \n",
       "2016-01-13  139.751599               0.0    ...       0   1    0    0    0   \n",
       "2016-01-14  139.751599               0.0    ...       0   1    0    0    0   \n",
       "2016-01-15  139.751599               0.0    ...       0   1    0    0    0   \n",
       "2016-01-16  139.751599               0.0    ...       0   1    0    0    0   \n",
       "2016-01-18  139.751599               0.0    ...       0   1    0    0    0   \n",
       "\n",
       "            May  Nov  Oct  Sep  forecast  \n",
       "visit_date                                \n",
       "2016-01-13    0    0    0    0       0.0  \n",
       "2016-01-14    0    0    0    0       0.0  \n",
       "2016-01-15    0    0    0    0       0.0  \n",
       "2016-01-16    0    0    0    0       0.0  \n",
       "2016-01-18    0    0    0    0       0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfSuper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01/15/2018 - Ben Grauer - changed over to the new style of loading all from the helper script\n",
    "visitMergeDF = dfSuper.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>calendar_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>genre_name</th>\n",
       "      <th>area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>...</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Mar</th>\n",
       "      <th>May</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Sep</th>\n",
       "      <th>forecast</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-13</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-14</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-15</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-16</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-18</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>Dining bar</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_store_id  visitors calendar_date day_of_week  \\\n",
       "visit_date                                                             \n",
       "2016-01-13  air_ba937bf13d40fb24      25.0    2016-01-13   Wednesday   \n",
       "2016-01-14  air_ba937bf13d40fb24      32.0    2016-01-14    Thursday   \n",
       "2016-01-15  air_ba937bf13d40fb24      29.0    2016-01-15      Friday   \n",
       "2016-01-16  air_ba937bf13d40fb24      22.0    2016-01-16    Saturday   \n",
       "2016-01-18  air_ba937bf13d40fb24       6.0    2016-01-18      Monday   \n",
       "\n",
       "            holiday_flg genre_name\\t                     area_name   latitude  \\\n",
       "visit_date                                                                      \n",
       "2016-01-13            0   Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "2016-01-14            0   Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "2016-01-15            0   Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "2016-01-16            0   Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "2016-01-18            0   Dining bar  Tōkyō-to Minato-ku Shibakōen  35.658068   \n",
       "\n",
       "             longitude  reserve_visitors    ...     Feb Jan  Jul  Jun  Mar  \\\n",
       "visit_date                                  ...                              \n",
       "2016-01-13  139.751599               0.0    ...       0   1    0    0    0   \n",
       "2016-01-14  139.751599               0.0    ...       0   1    0    0    0   \n",
       "2016-01-15  139.751599               0.0    ...       0   1    0    0    0   \n",
       "2016-01-16  139.751599               0.0    ...       0   1    0    0    0   \n",
       "2016-01-18  139.751599               0.0    ...       0   1    0    0    0   \n",
       "\n",
       "            May  Nov  Oct  Sep  forecast  \n",
       "visit_date                                \n",
       "2016-01-13    0    0    0    0       0.0  \n",
       "2016-01-14    0    0    0    0       0.0  \n",
       "2016-01-15    0    0    0    0       0.0  \n",
       "2016-01-16    0    0    0    0       0.0  \n",
       "2016-01-18    0    0    0    0       0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitMergeDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing==1:\n",
    "    testTS.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = 0\n",
    "if testing == 1:\n",
    "    \n",
    "    # Make a copy\n",
    "    #testTS = dfSuper.copy()\n",
    "    \n",
    "    storeToEvaluate = 'air_1c0b150f9e696a5f'\n",
    "    storeToEvaluate = 'air_55390f784018349a'\n",
    "\n",
    "    # make a copy\n",
    "    #testTS = dfSuper[dfSuper['air_store_id']==storeToEvaluate].copy()\n",
    "    testTS = dfSuper.loc[(dfSuper.index.get_level_values('air_store_id') == storeToEvaluate)]\n",
    "\n",
    "    # Reset just to the visit date\n",
    "    testTS.reset_index(level=0, inplace=True)\n",
    "    \n",
    "    testTS.asfreq('D')\n",
    "    print('done')\n",
    "\n",
    "    testTS['visitors_log'] = np.log(testTS['visitors'])\n",
    "\n",
    "\n",
    "    # ts.index = ts.index + pd.DateOffset(days=39)  # this was populating data?\n",
    "    # Re-initialize variables for function below  - 39 days\n",
    "    idx = pd.DataFrame(pd.date_range('2017-04-23','2017-05-31'), columns={'dateRange'})\n",
    "    idx.set_index('dateRange',inplace=True)\n",
    "    testTS = pd.concat([testTS,idx], axis=1)\n",
    "\n",
    "    # Impute\n",
    "    testTS['air_store_id'].replace({np.nan: storeToEvaluate}, inplace=True)\n",
    "    testTS['visitors'].replace({np.nan: 0}, inplace=True)\n",
    "    testTS['visitors_log'].replace({np.nan: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing == 1:\n",
    "    # Find Min Date\n",
    "    minDate = testTS.index.min()\n",
    "\n",
    "    testTS['visitors'][minDate:\"2017-04-23\"].plot()\n",
    "    testTS['visitors_log'][minDate:\"2017-04-23\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_run_TS_test(colName, modelName, tsParam):\n",
    "    minDate = testTS.index.min()\n",
    "\n",
    "    model = ARIMA(testTS['visitors'][minDate:\"2017-04-22\"], order=(tsParam))\n",
    "    modelFit = model.fit()\n",
    "    results = modelFit.forecast(39)\n",
    "\n",
    "    testTS[modelName] = 0\n",
    "    testTS[modelName][\"2017-04-23\":\"2017-05-31\"] = results[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing == 1:\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    fn_run_TS_test('visitors', 'forecast_7day_7,0,0', (7,0,0))\n",
    "    fn_run_TS_test('visitors', 'forecast_7day_7,1,0', (7,1,0))\n",
    "    fn_run_TS_test('visitors', 'forecast_14day_14,0,0', (14,0,0))\n",
    "    fn_run_TS_test('visitors', 'forecast_14day_14,1,0', (14,1,0))\n",
    "    #fn_run_TS_test('visitors', 'forecast_7day_7,1,0', (15,1,0))\n",
    "    fn_run_TS_test('visitors', 'forecast_14day_14,1,0', (14,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing == 1:\n",
    "    startTime = datetime.now()\n",
    "\n",
    "    # this looks alot better\n",
    "    fn_run_TS_test('31-day-SMA', 'forecast_31SMA_0,0,0', (31,0,0))\n",
    "\n",
    "    print(datetime.now() - startTime)\n",
    "    testTS[['visitors','forecast_31SMA_0,0,0']][\"2017-01-01\":\"2017-05-31\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing == 1:\n",
    "    from datetime import datetime\n",
    "    startTime = datetime.now()\n",
    "\n",
    "    # this looks alot better\n",
    "    fn_run_TS_test('7-day-SMA', 'forecast_7SMA_0,0,0', (31,0,0))\n",
    "\n",
    "    testTS[['visitors','forecast_7SMA_0,0,0']][\"2017-01-01\":\"2017-05-31\"].plot()       \n",
    "\n",
    "    print (datetime.now() - startTime) # about 13 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing == 1:\n",
    "    finalList = ['visitors','forecast_7day_7,0,0','forecast_7day_7,1,0','forecast_14day_14,0,0','forecast_14day_14,1,0',\n",
    "                '7-day-SMA','14-day-SMA','31-day-SMA']\n",
    "    testTS[finalList][\"2017-01-01\":\"2017-05-31\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if testing == 1:\n",
    "    #ts['forecast'][\"2017-04-23\":\"2017-05-31\"] = results_7day[0][:]\n",
    "    #ts['forecast_log'][\"2017-04-23\":\"2017-05-31\"] = resultsLog[0][:]\n",
    "    #ts['forecast_logExp'] = np.exp(ts['forecast_log'])  # Return Log back\n",
    "    #ts.plot()\n",
    "    #print(modelFit_7day.aic)\n",
    "\n",
    "    testTS['forecast'][\"2017-04-23\":\"2017-05-31\"] = results_15day[0][:]\n",
    "    testTS['forecast_log'][\"2017-04-23\":\"2017-05-31\"] = resultsLog[0][:]\n",
    "    testTS['forecast_logExp'] = np.exp(testTS['forecast_log'])  # Return Log back\n",
    "    testTS.plot()\n",
    "    print(modelFit_15day.aic)\n",
    "    print(modelLog_fit.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEGIN Main Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code Bock Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable to specify if we include a header one time in the files\n",
    "includeHeaderRunOnce = True\n",
    "# Determine if we are resuming a previous file\n",
    "resumeRunningPreviousFile = False\n",
    "\n",
    "\n",
    "#==================\n",
    "# Setup Directories\n",
    "#==================\n",
    "# if platform.system() == 'Windows':\n",
    "if platform == 'win32':\n",
    "    exportDirectory = directory + 'export\\\\'\n",
    "\n",
    "# Mac\n",
    "#elif platform.system() == 'Darwin':\n",
    "elif platform == 'darwin':\n",
    "    exportDirectory = directory + 'export/'\n",
    "\n",
    "# AWS\n",
    "elif platform == 'linux':\n",
    "    exportDirectory = directory + 'export/'\n",
    "\n",
    "#exportParamOptionsFileName = exportDirectory + 'export_param_' + str(file_args_store_nbr) + '.csv'\n",
    "exportResultsSubmissionFileName = exportDirectory + 'ARIMA_export_results.csv'\n",
    "\n",
    "exportLogName = exportDirectory + 'ARIMA_export_log.log'\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# SETUP LOGGING\n",
    "# ===========================\n",
    "# Wipe any existing log file - change to keep this script\n",
    "#if path.isfile(exportLogName):\n",
    "#    os.remove(exportLogName)\n",
    "\n",
    "# We may set another parameter to pass in to wipe the existing param options and results submissions\n",
    "\n",
    "# SEt logging information\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# create a file handler\n",
    "handler = logging.FileHandler(exportLogName)\n",
    "handler.setLevel(logging.INFO)\n",
    "\n",
    "# create a logging format\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# add the handlers to the logger\n",
    "logger.addHandler(handler)\n",
    "logger.info('Start Logging')\n",
    "\n",
    "\n",
    "# Find out if we have an existing file and work with it from there to update the mergedDataFrame\n",
    "includeSubmissionHeaderRunOnce = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a default running dataframe - to be used to grab unique values\n",
    "# ALWAYS NEEDS TO BE HERE\n",
    "rundf = visitMergeDF.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if we are resuming File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "# Check if the file exists\n",
    "def fn_determine_file_exists(fileName):\n",
    "    fileExists = False\n",
    "\n",
    "    if path.isfile(fileName):\n",
    "        fileExists = True\n",
    "\n",
    "    return  fileExists\n",
    "\n",
    "# Will determine where the file / process left off to pick back up\n",
    "def fn_determine_file_last_run(fileName, colNames):\n",
    "\n",
    "    # Read In\n",
    "    df_leftOff = pd.read_csv(fileName)\n",
    "    \n",
    "    # Grab the unique store number \n",
    "    df_leftOff = pd.DataFrame(df_leftOff['air_store_id'].unique(), columns=(colNames))\n",
    "    \n",
    "    # if I re-use this later, need to handle for multiple column names (if applicable)\n",
    "    df_leftOff.sort_values(['air_store_id'], ascending=[True], inplace=True)\n",
    "\n",
    "    # Set a Processed Flag for all the entries\n",
    "    df_leftOff['processed'] = 1\n",
    "\n",
    "    # Return a data frame to join later\n",
    "    return df_leftOff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if we are resuming a file\n",
    "# this could stand to be cleaned up.  \n",
    "\n",
    "# Call the function to determine where we left off\n",
    "if fn_determine_file_exists(exportResultsSubmissionFileName) == True:\n",
    "\n",
    "    # Repull\n",
    "    existingDF = fn_determine_file_last_run(exportResultsSubmissionFileName, ['air_store_id'])\n",
    "    print('Existing File detected with ' + str(len(existingDF)) + ' entries.')\n",
    "\n",
    "    # Join\n",
    "    resumeDF = pd.merge(rundf.reset_index(), existingDF, how='left', on='air_store_id', copy=True)\n",
    "    resumeDF['processed'].replace({np.nan: 0}, inplace=True)\n",
    "    resumeDF = resumeDF[resumeDF['processed']==0].copy()\n",
    "    resumeDF.set_index('visit_date', inplace=True)\n",
    "    \n",
    "    # Drop the processed flag here - future (or keep if need be)\n",
    "    \n",
    "    # re order\n",
    "    resumeDF.sort_values(['air_store_id'], ascending=[True], inplace=True)\n",
    "\n",
    "    # set to True for below\n",
    "    resumeRunningPreviousFile = True\n",
    "    \n",
    "    # Set the runnign dataframe to the resumed one\n",
    "    rundf = resumeDF.copy()\n",
    "\n",
    "# Determine if we include header (multiple booleans as I had split multiple output files earlier)\n",
    "if resumeRunningPreviousFile == True:\n",
    "    includeSubmissionHeaderRunOnce = False\n",
    "    \n",
    "# Re-Order - whether we are resuming or not\n",
    "rundf.sort_values(['air_store_id'], ascending=[True], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>calendar_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>genre_name</th>\n",
       "      <th>area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>...</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Mar</th>\n",
       "      <th>May</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Sep</th>\n",
       "      <th>forecast</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-07-01</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-17</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2017-02-17</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Chiyoda-ku Kudanminami</td>\n",
       "      <td>35.694003</td>\n",
       "      <td>139.753595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    air_store_id  visitors calendar_date day_of_week  \\\n",
       "visit_date                                                             \n",
       "2016-07-01  air_00a91d42b08b08d9      35.0    2016-07-01      Friday   \n",
       "2017-02-17  air_00a91d42b08b08d9      45.0    2017-02-17      Friday   \n",
       "\n",
       "            holiday_flg    genre_name\\t                        area_name  \\\n",
       "visit_date                                                                 \n",
       "2016-07-01            0  Italian/French  Tōkyō-to Chiyoda-ku Kudanminami   \n",
       "2017-02-17            0  Italian/French  Tōkyō-to Chiyoda-ku Kudanminami   \n",
       "\n",
       "             latitude   longitude  reserve_visitors    ...     Feb Jan  Jul  \\\n",
       "visit_date                                             ...                    \n",
       "2016-07-01  35.694003  139.753595               1.0    ...       0   0    1   \n",
       "2017-02-17  35.694003  139.753595               0.0    ...       1   0    0   \n",
       "\n",
       "            Jun  Mar  May  Nov  Oct  Sep  forecast  \n",
       "visit_date                                          \n",
       "2016-07-01    0    0    0    0    0    0       0.0  \n",
       "2017-02-17    0    0    0    0    0    0       0.0  \n",
       "\n",
       "[2 rows x 48 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rundf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through all records - function first, then loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_run_arima_timeseries(storeToEvaluate, orderList):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    errorOccured = False\n",
    "    \n",
    "    if GLOBAL_CONST_DEBUG ==1:\n",
    "        print('Start Processing Restaraunt: ' + str(storeToEvaluate))\n",
    "    \n",
    "    # create ts sub-set\n",
    "    ts = visitMergeDF[visitMergeDF['air_store_id']==storeToEvaluate].copy()\n",
    "    ts.asfreq('D')\n",
    "    \n",
    "    minDate = ts.index.min()\n",
    "    maxDate = ts.index.max()\n",
    "    \n",
    "    # add dates to predict\n",
    "    idx = pd.DataFrame(pd.date_range('2017-04-23','2017-05-31'), columns={'dateRange'})\n",
    "    idx.set_index('dateRange',inplace=True)\n",
    "    ts = pd.concat([ts,idx], axis=1)\n",
    "\n",
    "    # Impute\n",
    "    ts['air_store_id'].replace({np.nan: storeToEvaluate}, inplace=True)\n",
    "    ts['visitors'].replace({np.nan: 0}, inplace=True)\n",
    "    # 01/15/2018 - Ben Grauer - took out\n",
    "    #ts['visitors_log'].replace({np.nan: 0}, inplace=True)\n",
    "    \n",
    "    # Try Catch Here\n",
    "    try:\n",
    "    \n",
    "        # standard ARIMA model with order list passed in\n",
    "        # 01/15/2018 - Ben Grauer - change from 23 to 22\n",
    "        model = ARIMA(ts['visitors'][minDate:\"2017-04-22\"], order=orderList)\n",
    "        modelFit = model.fit(disp=-1)\n",
    "        # 39 days is how far out we are predicting\n",
    "        results = modelFit.forecast(39)  \n",
    "        # set forecast\n",
    "        ts['forecast'][\"2017-04-23\":\"2017-05-31\"] = results[0][:]\n",
    "\n",
    "        if GLOBAL_CONST_DEBUG ==1:\n",
    "            print('Start Processing Restaraunt - LOG: ' + str(storeToEvaluate))\n",
    "\n",
    "        # 01/15/2018 - Ben Grauer - remove log\n",
    "        # Do the log while we are in here\n",
    "        #modelLog = ARIMA(ts['visitors_log'][minDate:\"2017-04-23\"], order=orderList)\n",
    "        #modelLog_fit = modelLog.fit(disp=-1)\n",
    "        #resultsLog = modelLog_fit.forecast(39)\n",
    "        #ts['forecast_log'][\"2017-04-23\":\"2017-05-31\"] = resultsLog[0][:]\n",
    "        #ts['forecast_logExp'] = np.exp(ts['forecast_log'])  # Revert log back to standard\n",
    "    \n",
    "    except: \n",
    "        #(RuntimeError, TypeError, NameError):\n",
    "        #print('Error')\n",
    "        #print(RuntimeError)\n",
    "        #print(TypeError)\n",
    "        #print(NameError)\n",
    "        #print('\\n')\n",
    "        logger.info('Error processing store: ' + storeToEvaluate)\n",
    "        errorOccured = True\n",
    "        \n",
    "        if str(maxDate) == \"2017-04-22 00:00:00\":\n",
    "            smaSevenDays = ts['SMA_7_days'][\"2017-04-22\":\"2017-04-22\"][0]\n",
    "            #dfTSReturn = ts[:][\"2017-04-23\":\"2017-05-31\"]\n",
    "            ts['forecast'] = smaSevenDays\n",
    "        else:\n",
    "            # restaraunt has likely shut down\n",
    "            ts['forecast'] = 0\n",
    "           \n",
    "    pass\n",
    "\n",
    "    if GLOBAL_CONST_DEBUG ==1:\n",
    "        print('Finished Processing Restaraunt: ' + str(storeToEvaluate))\n",
    "\n",
    "    # return back only what we predicted\n",
    "    dfTSReturn = ts[:][\"2017-04-23\":]\n",
    "    return dfTSReturn, errorOccured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records to Process: 829\n",
      "Processing Index: 0 - Store ID: air_00a91d42b08b08d9 - Elapsed Time: 0:00:00\n",
      "Processing Index: 300 - Store ID: air_629edf21ea38ac2d - Elapsed Time: 0:00:35.445151\n",
      "Processing Index: 600 - Store ID: air_b8d9e1624baaadc2 - Elapsed Time: 0:01:12.002583\n",
      "\n",
      "\n",
      "Finished All Records\n",
      "Time to Finish: 0:01:39.977227\n"
     ]
    }
   ],
   "source": [
    "# Get all Unique Visits\n",
    "visitStoreArr = rundf['air_store_id'].unique()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# 12/28/2017 - This is the first order list I want to go with\n",
    "# orderList = (15,1,0)\n",
    "# 12/29/2017 - This is the second list (really want the log values)\n",
    "# orderList = (20,1,0)\n",
    "# 01/15/2018 - Attemp 31 - test with 3\n",
    "orderList = (31,0,0)\n",
    "\n",
    "# print(orderList)\n",
    "\n",
    "# Default to the max of the array\n",
    "maxLoopRun = len(visitStoreArr)\n",
    "\n",
    "# if we are testing\n",
    "testRun = 0\n",
    "if testRun > 0:\n",
    "    maxLoopRun = testRun\n",
    "    includeSubmissionHeaderRunOnce = True\n",
    "    # Test an error\n",
    "    #visitStoreArr = ('air_1c0b150f9e696a5f')\n",
    "\n",
    "print('Total Records to Process: ' + str(maxLoopRun))\n",
    "startTime = datetime.now()\n",
    "\n",
    "i=0\n",
    "while i < maxLoopRun: \n",
    "    \n",
    "    #if i%300==0:\n",
    "    if i%300==0:\n",
    "        print('Processing Index: ' + str(i) + ' - Store ID: ' + visitStoreArr[i] + \n",
    "              ' - Elapsed Time: ' + str(datetime.now() - startTime))\n",
    "    \n",
    "    # Log Start\n",
    "    logger.info('Start Index: ' + str(i) + ' - Restaraunt: ' + str(visitStoreArr[i]))\n",
    "    \n",
    "    # Run TS\n",
    "    dfTsRun, bError = fn_run_arima_timeseries(visitStoreArr[i], orderList)\n",
    "    \n",
    "    # handle error in side for this script\n",
    "    # if bError == True: \n",
    "    \n",
    "    dfTsRun.reset_index(inplace=True)\n",
    "    dfTsRun = dfTsRun[['index','air_store_id','visitors','forecast']]\n",
    "    # colNames = ('visit_date','air_store_id','visitors','visitors_log','forecast','forecast_log','forecast_logExp')\n",
    "    dfTsRun = dfTsRun.rename(columns={'index': 'visit_date'})\n",
    "    \n",
    "    with open(exportResultsSubmissionFileName, 'a') as f:\n",
    "        dfTsRun.to_csv(f, header=includeSubmissionHeaderRunOnce, index=False, quotechar='\"')\n",
    "        f.close()\n",
    "        includeSubmissionHeaderRunOnce = False\n",
    "    \n",
    "    # Log Start\n",
    "    logger.info('Finish Index: ' + str(i) + ' - Restaraunt: ' + str(visitStoreArr[i]))\n",
    "    \n",
    "    # increment\n",
    "    i=i+1\n",
    "    \n",
    "print('\\n')\n",
    "print('Finished All Records')\n",
    "print ('Time to Finish: ' + str(datetime.now() - startTime)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfTsRun.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Final step to massage the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Stop Logging')\n",
    "handlers = logger.handlers\n",
    "for handler in handlers:\n",
    "    handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUBMISSION FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull the results and formulate files\n",
    "# Must have exact number in sample submission.  Not everything contained in training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "arimaExportDir = 'D:\\\\project\\\\data\\\\kg_jpn_rest\\\\export\\\\'\n",
    "arimaExportFile = 'ARIMA_export_results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "armRsltDF = pd.read_csv(arimaExportDir + arimaExportFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_date</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.760641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.629389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.576147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visit_date          air_store_id  visitors   forecast\n",
       "0  2017-04-23  air_00a91d42b08b08d9       0.0  21.760641\n",
       "1  2017-04-24  air_00a91d42b08b08d9       0.0  23.629389\n",
       "2  2017-04-25  air_00a91d42b08b08d9       0.0  27.576147"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(str(len(armRsltDF)))\n",
    "armRsltDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the fields to create the ID\n",
    "armRsltDF['id'] = ''\n",
    "armRsltDF['id'] = armRsltDF['id'].str.cat(armRsltDF['air_store_id'])\n",
    "armRsltDF['id'] = armRsltDF['id'] + '_'\n",
    "armRsltDF['id'] = armRsltDF['id'].str.cat(armRsltDF['visit_date'].astype(str))\n",
    "\n",
    "# Drop the visitors (will rename later)\n",
    "armRsltDF.drop('visitors', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_date</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>forecast</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>21.760641</td>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>23.629389</td>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>27.576147</td>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visit_date          air_store_id   forecast  \\\n",
       "0  2017-04-23  air_00a91d42b08b08d9  21.760641   \n",
       "1  2017-04-24  air_00a91d42b08b08d9  23.629389   \n",
       "2  2017-04-25  air_00a91d42b08b08d9  27.576147   \n",
       "\n",
       "                                id  \n",
       "0  air_00a91d42b08b08d9_2017-04-23  \n",
       "1  air_00a91d42b08b08d9_2017-04-24  \n",
       "2  air_00a91d42b08b08d9_2017-04-25  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "armRsltDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must turn any negatives into a zero\n",
    "def fn_set_negative_to_zero(col):\n",
    "    if col < 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return col\n",
    "\n",
    "# 01/15/2018 - Ben Grauer - only use forecast\n",
    "armRsltDF['forecast'] = armRsltDF.apply(lambda row: fn_set_negative_to_zero(row['forecast']), axis=1)\n",
    "#armRsltDF['forecast_log'] = armRsltDF.apply(lambda row: fn_set_negative_to_zero(row['forecast_log']), axis=1)\n",
    "#armRsltDF['forecast_logExp'] = armRsltDF.apply(lambda row: fn_set_negative_to_zero(row['forecast_logExp']), axis=1)\n",
    "\n",
    "#armRsltDF['forecast_log'] = armRsltDF['forecast_log'].replace(np.nan, 0, regex=True)\n",
    "#armRsltDF['forecast_logExp'] = armRsltDF['forecast_logExp'].replace(np.nan, 0, regex=True)\n",
    "\n",
    "#armRsltDF[armRsltDF['forecast']<0]['forecast'] = 0.0\n",
    "#armRsltDF[armRsltDF['forecast_log']<0]['forecast_log'] = 0.0\n",
    "#armRsltDF[armRsltDF['forecast_logExp']<0]['forecast_logExp'] = 0.0\n",
    "\n",
    "#armRsltDF['forecast_rnd'] = np.round(armRsltDF['forecast'])\n",
    "#armRsltDF['forecast_logExp_rnd'] = np.round(armRsltDF['forecast_logExp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to sample submission\n",
    "armRsltDF = pd.merge(pd_sample_submission, armRsltDF, how='inner', on=('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32019"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the visitors (will rename later)\n",
    "armRsltDF.drop('visitors', axis=1, inplace=True)\n",
    "\n",
    "# 32019 - correct length\n",
    "len(armRsltDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>forecast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>21.760641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>23.629389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>27.576147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visit_date          air_store_id  \\\n",
       "0  air_00a91d42b08b08d9_2017-04-23  2017-04-23  air_00a91d42b08b08d9   \n",
       "1  air_00a91d42b08b08d9_2017-04-24  2017-04-24  air_00a91d42b08b08d9   \n",
       "2  air_00a91d42b08b08d9_2017-04-25  2017-04-25  air_00a91d42b08b08d9   \n",
       "\n",
       "    forecast  \n",
       "0  21.760641  \n",
       "1  23.629389  \n",
       "2  27.576147  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "armRsltDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_write_submission_file(df, colNames, fileName):\n",
    "    \n",
    "    print(colNames[1])\n",
    "    forecastCol = colNames[1]\n",
    "    \n",
    "    tempDF = df.copy()\n",
    "    \n",
    "    # Rename the second column to \"visitors\" as per submission\n",
    "    tempDF.rename(columns={forecastCol: 'visitors'}, inplace=True)\n",
    "    \n",
    "    #print(tempDF.head())\n",
    "    tempDF.to_csv(fileName, header=True, index=False, quotechar='\"', columns=('id','visitors'))\n",
    "    print('Wrote file: ' + fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecast\n",
      "Wrote file: D:\\project\\data\\kg_jpn_rest\\export\\20180325ARIMA_subm_frcst.csv\n"
     ]
    }
   ],
   "source": [
    "todayDate = str(dt.date.today().strftime('%Y%m%d'))\n",
    "\n",
    "# Float forecast\n",
    "exportDF = armRsltDF.copy()\n",
    "exportDF\n",
    "columns=('id','forecast')\n",
    "fn_write_submission_file(armRsltDF, columns, arimaExportDir + todayDate + 'ARIMA_subm_frcst.csv')\n",
    "\n",
    "# These ended up making no difference in the score, so took them out\n",
    "# Rounded Forecast\n",
    "#columns=('id','forecast_rnd')\n",
    "#fn_write_submission_file(armRsltDF, columns, arimaExportDir + todayDate + '_subm_frcst_rnd.csv')\n",
    "\n",
    "# Log Forecast\n",
    "#columns=('id','forecast_logExp')\n",
    "#fn_write_submission_file(armRsltDF, columns, arimaExportDir + todayDate + '_subm_frcst_log_flt.csv')\n",
    "\n",
    "# Log Rounded Forecast\n",
    "#columns=('id','forecast_logExp_rnd')\n",
    "#fn_write_submission_file(armRsltDF, columns, arimaExportDir + todayDate + '_subm_frcst_log_rnd.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
